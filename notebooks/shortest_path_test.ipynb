{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27465091-dc22-4edd-a05b-c1a679789a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import decision_learning.data.shortest_path_grid\n",
    "importlib.reload(decision_learning.data.shortest_path_grid)\n",
    "from decision_learning.data.shortest_path_grid import piecewise_linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00546497-a12e-4a11-8234-ae58cb7b97e7",
   "metadata": {},
   "source": [
    "### Testing Piecewise Linear Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d305ece6-f64b-469a-8189-a1650282b9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-30 08:49:39,155 - decision_learning.data.shortest_path_grid - DEBUG - chg_pt: 0.55\n",
      "2024-10-30 08:49:39,158 - decision_learning.data.shortest_path_grid - DEBUG - chg_pt: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f9ecd70f390>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnd = np.random.RandomState(1)\n",
    "x = rnd.uniform(low=0, \n",
    "            high=2, \n",
    "            size=1000)\n",
    "y_red = piecewise_linear(x,\n",
    "                    slope0=4, \n",
    "                    int0=0,\n",
    "                    slope1=0, \n",
    "                    int1=2.2)\n",
    "y_blue = piecewise_linear(x,\n",
    "                    slope0=0, \n",
    "                    int0=2.2,\n",
    "                    slope1=0, \n",
    "                    int1=2.2)\n",
    "plt.scatter(x, y_red)\n",
    "plt.scatter(x, y_blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8abcbb4b-2339-4080-bfbe-07a1db5cacd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume list1 and list2 are your lists of arrays\n",
    "list1 = np.array([1, 2, 3]) \n",
    "list2 = np.array([4, 5, 6])\n",
    "\n",
    "# Concatenate the lists\n",
    "combined = np.concatenate((list1,list2))\n",
    "\n",
    "# # Create an array of all possible indices\n",
    "# all_indices = np.arange(max(combined) + 1)\n",
    "\n",
    "# # Find the indices not in the combined list\n",
    "# not_in_combined = np.setdiff1d(all_indices, combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f323e2c4-35f8-4eb7-99dd-8b65dbabe58f",
   "metadata": {},
   "source": [
    "# Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d35609b6-2eb4-47df-8647-e637f3719533",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(decision_learning.data.shortest_path_grid)\n",
    "from decision_learning.data.shortest_path_grid import add_noise, genDataPlant, shortest_path_synthetic_sym_no_noise, shortest_path_synthetic_plant_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "670c0fb9-82ec-43a7-8a40-300c1de3ae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_arr = torch.randperm(100000)\n",
    "indices_arr_test = torch.randperm(100000)\n",
    "\n",
    "sim = 0\n",
    "n_arr = [200, 400, 800, 1600]\n",
    "ep_arr = ['unif', 'normal']\n",
    "trials = 100\n",
    "\n",
    "exp_arr = []\n",
    "for n in n_arr:\n",
    "    for ep in ep_arr:\n",
    "        for t in range(trials):\n",
    "            exp_arr.append([n, ep, t])\n",
    "\n",
    "exp = exp_arr[sim]\n",
    "ep_type = exp[1]\n",
    "trial = exp[2]\n",
    "\n",
    "# generate data\n",
    "grid = (5, 5)  # grid size\n",
    "num_data = exp[0]  # number of training data\n",
    "num_feat = 5  # size of feature\n",
    "deg = 6  # polynomial degree\n",
    "e = .4  # noise width\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2f89e12-120c-44e2-9578-67299153e866",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(decision_learning.data.shortest_path_grid)\n",
    "from decision_learning.data.shortest_path_grid import add_noise, genData, genDataPlant, shortest_path_synthetic_sym_no_noise, shortest_path_synthetic_plant_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43cac67e-32c9-4a93-a3fd-1946f7f78afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "planted_good_pwl_params = {'slope0':0, \n",
    "                    'int0':2,\n",
    "                    'slope1':0, \n",
    "                    'int1':2}\n",
    "planted_bad_pwl_params = {'slope0':4, \n",
    "                    'int0':0,\n",
    "                    'slope1':0, \n",
    "                    'int1':2.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2d2b284-e0da-413b-a8e1-4dd23d6c5c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-30 08:49:40,945 - decision_learning.data.shortest_path_grid - DEBUG - good_bad_edges: [ 1  4  9 16 24 31 36 39  0  3  8 15 23 30 35 38], remain_edges: [ 2  5  6  7 10 11 12 13 14 17 18 19 20 21 22 25 26 27 28 29 32 33 34 37]\n",
      "2024-10-30 08:49:40,946 - decision_learning.data.shortest_path_grid - DEBUG - chg_pt: 0.0\n",
      "2024-10-30 08:49:40,947 - decision_learning.data.shortest_path_grid - DEBUG - chg_pt: 0.55\n"
     ]
    }
   ],
   "source": [
    "data = shortest_path_synthetic_sym_no_noise(num_data=num_data+200,\n",
    "        num_features=num_feat, \n",
    "        grid=grid, \n",
    "        deg=deg, \n",
    "        seed=indices_arr[trial])\n",
    "\n",
    "\n",
    "data_plant = shortest_path_synthetic_plant_path(planted_good_pwl_params=planted_good_pwl_params,\n",
    "                                   planted_bad_pwl_params=planted_bad_pwl_params,\n",
    "                                   seed=indices_arr[trial],\n",
    "                                   **data)\n",
    "data_noise = add_noise(c=data_plant['c_plant'],\n",
    "          noise_type=ep_type,\n",
    "          noise_width=e,\n",
    "          seed=indices_arr[trial])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626ec459-2a6f-45b0-ad4f-1da2ffc663b3",
   "metadata": {},
   "source": [
    "One genData Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7c66e02-6f27-4d7b-b3fc-5bc3ee1bdce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = genData(num_data=num_data+200,\n",
    "        num_features=num_feat, \n",
    "        grid=grid, \n",
    "        deg=deg, \n",
    "        noise_type=ep_type,\n",
    "        noise_width=e,\n",
    "        seed=indices_arr[trial],     \n",
    "        plant_edges=False,\n",
    "        planted_good_pwl_params=planted_good_pwl_params,\n",
    "        planted_bad_pwl_params=planted_bad_pwl_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e38f4015-fa7b-4b9a-b8c0-dfa891921c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 40)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data['cost'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68ada215-6859-4f7b-bbbb-7b201ce626cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import decision_learning.modeling.models\n",
    "importlib.reload(decision_learning.modeling.models)\n",
    "from decision_learning.modeling.models import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96e851ce-de37-4b23-a6dc-73c6b51f2dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_mod = LinearRegression(input_dim=final_data['feat'].shape[1],\n",
    "                 output_dim=final_data['cost'].shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1ecaaf9-3d36-438a-ae03-5a5615b39e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_pred = lr_mod(torch.tensor(final_data['feat'], dtype=torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84a93808-214f-411c-9d71-772b35aa9795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.5614e-01, -8.1670e-04, -1.6145e-01,  ..., -5.1179e-01,\n",
       "          1.1820e-01, -4.9448e-01],\n",
       "        [-1.0494e-01,  7.3423e-01,  3.3650e-01,  ...,  5.0490e-01,\n",
       "          9.1026e-01,  7.2220e-01],\n",
       "        [ 6.7327e-01,  6.6797e-01, -1.9701e-01,  ..., -1.4250e+00,\n",
       "         -3.4055e-01, -5.9946e-02],\n",
       "        ...,\n",
       "        [ 1.0182e+00, -1.0435e+00,  4.9286e-01,  ..., -1.3806e+00,\n",
       "         -5.8206e-01, -1.1913e+00],\n",
       "        [ 8.4221e-01, -1.9684e-01, -3.5824e-01,  ..., -5.4777e-01,\n",
       "         -4.4760e-01, -9.9908e-01],\n",
       "        [ 1.3897e+00,  3.9766e-01,  3.0643e-01,  ..., -4.8733e-01,\n",
       "         -1.0998e+00, -2.9522e-01]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4178fb57-45b4-4204-a1d5-5e7d4363a927",
   "metadata": {},
   "source": [
    "# Initial Solution using optimization Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5119ebd3-9b04-467e-a831-ebf61b4b98ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-Sklearn cannot be imported.\n"
     ]
    }
   ],
   "source": [
    "from pyepo.model.opt import optModel\n",
    "from pyepo import EPO\n",
    "\n",
    "def shortest_path_solver(costs, size, sens = 1e-4):\n",
    "    # Forward Pass\n",
    "    starting_ind = 0\n",
    "    starting_ind_c = 0\n",
    "    samples = costs.shape[0]\n",
    "    V_arr = torch.zeros(samples, size ** 2)\n",
    "    for i in range(0, 2 * (size - 1)):\n",
    "        num_nodes = min(i + 1, 9 - i)\n",
    "        num_nodes_next = min(i + 2, 9 - i - 1)\n",
    "        num_arcs = 2 * (max(num_nodes, num_nodes_next) - 1)\n",
    "        V_1 = V_arr[:, starting_ind:starting_ind + num_nodes]\n",
    "        layer_costs = costs[:, starting_ind_c:starting_ind_c + num_arcs]\n",
    "        l_costs = layer_costs[:, 0::2]\n",
    "        r_costs = layer_costs[:, 1::2]\n",
    "        next_V_val_l = torch.ones(samples, num_nodes_next) * float('inf')\n",
    "        next_V_val_r = torch.ones(samples, num_nodes_next) * float('inf')\n",
    "        if num_nodes_next > num_nodes:\n",
    "            next_V_val_l[:, :num_nodes_next - 1] = V_1 + l_costs\n",
    "            next_V_val_r[:, 1:num_nodes_next] = V_1 + r_costs\n",
    "        else:\n",
    "            next_V_val_l = V_1[:, :num_nodes_next] + l_costs\n",
    "            next_V_val_r = V_1[:, 1:num_nodes_next + 1] + r_costs\n",
    "        next_V_val = torch.minimum(next_V_val_l, next_V_val_r)\n",
    "        V_arr[:, starting_ind + num_nodes:starting_ind + num_nodes + num_nodes_next] = next_V_val\n",
    "\n",
    "        starting_ind += num_nodes\n",
    "        starting_ind_c += num_arcs\n",
    "\n",
    "    # Backward Pass\n",
    "    starting_ind = size ** 2\n",
    "    starting_ind_c = costs.shape[1]\n",
    "    prev_act = torch.ones(samples, 1)\n",
    "    sol = torch.zeros(costs.shape)\n",
    "    for i in range(2 * (size - 1), 0, -1):\n",
    "        num_nodes = min(i + 1, 9 - i)\n",
    "        num_nodes_next = min(i, 9 - i + 1)\n",
    "        V_1 = V_arr[:, starting_ind - num_nodes:starting_ind]\n",
    "        V_2 = V_arr[:, starting_ind - num_nodes - num_nodes_next:starting_ind - num_nodes]\n",
    "\n",
    "        num_arcs = 2 * (max(num_nodes, num_nodes_next) - 1)\n",
    "        layer_costs = costs[:, starting_ind_c - num_arcs: starting_ind_c]\n",
    "\n",
    "        if num_nodes < num_nodes_next:\n",
    "            l_cs_res = ((V_2[:, :num_nodes_next - 1] - V_1 + layer_costs[:, ::2]) < sens) * prev_act\n",
    "            r_cs_res = ((V_2[:, 1:num_nodes_next] - V_1 + layer_costs[:, 1::2]) < sens) * prev_act\n",
    "            prev_act = torch.zeros(V_2.shape)\n",
    "            prev_act[:, :num_nodes_next - 1] += l_cs_res\n",
    "            prev_act[:, 1:num_nodes_next] += r_cs_res\n",
    "        else:\n",
    "            l_cs_res = ((V_2 - V_1[:, :num_nodes - 1] + layer_costs[:, ::2]) < sens) * prev_act[:, :num_nodes - 1]\n",
    "            r_cs_res = ((V_2 - V_1[:, 1:num_nodes] + layer_costs[:, 1::2]) < sens) * prev_act[:, 1:num_nodes]\n",
    "            prev_act = torch.zeros(V_2.shape)\n",
    "            prev_act += l_cs_res\n",
    "            prev_act += r_cs_res\n",
    "        cs = torch.zeros(layer_costs.shape)\n",
    "        cs[:, ::2] = l_cs_res\n",
    "        cs[:, 1::2] = r_cs_res\n",
    "        sol[:, starting_ind_c - num_arcs: starting_ind_c] = cs\n",
    "\n",
    "        starting_ind = starting_ind - num_nodes\n",
    "        starting_ind_c = starting_ind_c - num_arcs\n",
    "    # Dimension (samples, num edges)\n",
    "    obj = torch.sum(sol * costs, axis=1)\n",
    "    # Dimension (samples, 1)\n",
    "    return sol, obj.reshape(-1,1)\n",
    "\n",
    "# optimization model\n",
    "class optGenModel(optModel):\n",
    "    \"\"\"\n",
    "    This is an abstract class for Pyomo-based optimization model\n",
    "\n",
    "    Attributes:\n",
    "        _model (PyOmo model): Pyomo model\n",
    "        solver (str): optimization solver in the background\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            solver (str): optimization solver in the background\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # init obj\n",
    "        if self._model.modelSense == EPO.MINIMIZE:\n",
    "            self.modelSense = EPO.MINIMIZE\n",
    "        if self._model.modelSense == EPO.MAXIMIZE:\n",
    "            self.modelSense = EPO.MAXIMIZE\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"optGenModel \" + self.__class__.__name__\n",
    "\n",
    "    def setObj(self, c):\n",
    "        \"\"\"\n",
    "        A method to set objective function\n",
    "\n",
    "        Args:\n",
    "            c (np.ndarray / list): cost of objective function\n",
    "        \"\"\"\n",
    "        self._model.costvec = c\n",
    "\n",
    "    def copy(self):\n",
    "        \"\"\"\n",
    "        A method to copy model\n",
    "\n",
    "        Returns:\n",
    "            optModel: new copied model\n",
    "        \"\"\"\n",
    "        new_model = copy(self)\n",
    "        return new_model\n",
    "\n",
    "    def addConstr(self):\n",
    "        new_model = self.copy()\n",
    "        # add constraint\n",
    "        return new_model\n",
    "\n",
    "class modelclass():\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "        self.costvec = None\n",
    "        self.modelSense = EPO.MINIMIZE\n",
    "        self.x = np.ones(2 * size * (size - 1))\n",
    "class shortestPathModel(optGenModel):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.grid = (5,5)\n",
    "        super().__init__()\n",
    "\n",
    "    def _getModel(self):\n",
    "        \"\"\"\n",
    "        A method to build Gurobi model\n",
    "\n",
    "        Returns:\n",
    "            tuple: optimization model and variables\n",
    "        \"\"\"\n",
    "        m = modelclass(self.grid[0])\n",
    "        x = m.x\n",
    "        # sense\n",
    "        m.modelSense = EPO.MINIMIZE\n",
    "        return m, x\n",
    "\n",
    "    def solve(self):\n",
    "        sol, obj = shortest_path_solver(self._model.costvec.reshape(-1,len(self.x)), self._model.size)\n",
    "        return sol, obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf039593-afa6-4433-a39e-6e4ae00b4854",
   "metadata": {},
   "source": [
    "checking functionality of just `shortest_path_solver` vs `shortestPathModel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f157f39-17cc-4873-8d55-1ffbce65edd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optmodel = shortestPathModel()\n",
    "optmodel.setObj(c_pred)\n",
    "ptb_sols, ptb_obj = optmodel.solve()\n",
    "sol, obj = shortest_path_solver(costs=c_pred, size=5)\n",
    "\n",
    "torch.all(ptb_sols == sol).item(), torch.all(ptb_obj == obj).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68eee2ac-1b83-4c54-8ae8-539c1bbc0f57",
   "metadata": {},
   "source": [
    "# Create Dataset Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e5b62b4b-de57-4b22-bb43-4c4f685be26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import decision_learning.modeling.loss\n",
    "importlib.reload(decision_learning.modeling.loss)\n",
    "from decision_learning.modeling.loss import SPODataset, SPOPlus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f1b91b6-a2cb-405f-95fe-21be3c4903d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/yongpeng/decision-focused-learning/src/decision_learning/modeling/loss.py:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.true_sol = torch.tensor(true_sol, dtype=torch.float32) #if not isinstance(true_sol, torch.Tensor) else true_sol\n",
      "/home1/yongpeng/decision-focused-learning/src/decision_learning/modeling/loss.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.true_obj = torch.tensor(true_obj, dtype=torch.float32) #if not isinstance(true_obj, torch.Tensor) else true_obj\n"
     ]
    }
   ],
   "source": [
    "# get initial \n",
    "final_data = genData(num_data=num_data+200,\n",
    "        num_features=num_feat, \n",
    "        grid=grid, \n",
    "        deg=deg, \n",
    "        noise_type=ep_type,\n",
    "        noise_width=e,\n",
    "        seed=indices_arr[trial],     \n",
    "        plant_edges=False,\n",
    "        planted_good_pwl_params=planted_good_pwl_params,\n",
    "        planted_bad_pwl_params=planted_bad_pwl_params)\n",
    "\n",
    "sol, obj = shortest_path_solver(costs=final_data['cost'], size=5)\n",
    "\n",
    "dataset = SPODataset(X=final_data['feat'],\n",
    "           true_cost=final_data['cost'],\n",
    "           true_sol=sol,\n",
    "           true_obj=obj)\n",
    "dataloader = DataLoader(dataset, \n",
    "                        batch_size=len(dataset), \n",
    "                        shuffle=True,\n",
    "                       collate_fn=dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a3467a-52a0-4845-b03a-19fd05ccc448",
   "metadata": {},
   "source": [
    "Iterate over dataloader example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0164f8d-bd68-4645-a2bd-1a80adf0e567",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 128.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0, batch keys dict_keys(['X', 'true_cost', 'true_sol', 'true_obj'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over batches with tqdm progress bar\n",
    "for batch_idx, batch in enumerate(tqdm(dataloader)):\n",
    "    # Training/evaluation code here\n",
    "    # For example, passing inputs to a model\n",
    "    print(f\"Batch {batch_idx}, batch keys {batch.keys()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a05db1-1b91-4f8a-99b4-ccfc686b6ee7",
   "metadata": {},
   "source": [
    "# Instantiate Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951d4083-e733-4d75-bdda-51edec99152b",
   "metadata": {},
   "source": [
    "## Verify Loss is Same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8747d3e4-2f4a-4f94-9810-64d71a4fe533",
   "metadata": {},
   "source": [
    "One training loop example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1aa706ad-b867-4257-90e2-325239d802c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "def filter_kwargs(func, kwargs):\n",
    "    signature = inspect.signature(func)\n",
    "    valid_args = {key: value for key, value in kwargs.items() if key in signature.parameters}\n",
    "    return valid_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d0daf825-22b8-47e9-a498-0443fb726fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "lr_mod = LinearRegression(input_dim=final_data['feat'].shape[1],\n",
    "                 output_dim=final_data['cost'].shape[1])\n",
    "# set adam optimizer\n",
    "optimizer = torch.optim.Adam(lr_mod.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62d173b-56c4-4570-b635-2cc4ae8311a9",
   "metadata": {},
   "source": [
    "Double Check Loss Function is Implemented correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0ecb0426-6d11-4ea3-a030-6f5eef07f2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = lr_mod(batch['X'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c09172-f043-4699-a734-de1cddec38fb",
   "metadata": {},
   "source": [
    "Original Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "714e1240-f1b8-49c1-a8e9-52f4ad65d3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of cores: 1\n"
     ]
    }
   ],
   "source": [
    "from decision_learning.modeling.loss import SPOPlus2_O\n",
    "optmodel = shortestPathModel()\n",
    "orig_loss_fn = SPOPlus2_O(optmodel=optmodel)\n",
    "orig_loss = orig_loss_fn(pred_cost=cp, \n",
    "                         true_cost=batch['true_cost'], \n",
    "                         true_sol=batch['true_sol'], \n",
    "                         true_obj=batch['true_obj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "58368dad-d353-4301-8284-ca1881390a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = SPOPlus(optmodel=partial(shortest_path_solver,size=5))\n",
    "\n",
    "new_batch = filter_kwargs(loss_fn.forward, batch)\n",
    "loss2 = loss_fn(pred_cost=cp, **new_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0628afab-e9bb-4d16-9e66-7d26cb3c57bc",
   "metadata": {},
   "source": [
    "Check Original Implementation and New have same loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d75f681c-6bc4-43f1-85ca-e93bdd4becfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(12.0687, grad_fn=<MeanBackward0>),\n",
       " tensor(12.0687, grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(orig_loss, loss2)\n",
    "orig_loss == loss2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35215476-4894-4949-b508-0f76816a2994",
   "metadata": {},
   "source": [
    "Check Original and New have same gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433cc0e8-0f72-4dbd-81bc-e09e6a721de9",
   "metadata": {},
   "source": [
    "# Train Loop\n",
    "1. Get current batch (requires a dataset object and dataloader)\n",
    "2. Get Predictions\n",
    "3. Get necessary components for loss function like current predicted cost solutions\n",
    "4. Calculate loss function and back propogate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3135f56b-446f-456f-af5a-c16f336d9da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_mod_o = LinearRegression(input_dim=final_data['feat'].shape[1],\n",
    "                 output_dim=final_data['cost'].shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f408ddbb-5135-4868-84cf-cb8b8b3d8716",
   "metadata": {},
   "source": [
    "New Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "61400555-3a25-4130-b41e-cb1cc6c03053",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import copy\n",
    "\n",
    "# Assuming `model` is the original model you want to copy\n",
    "lr_mod = copy.deepcopy(lr_mod_o)\n",
    "\n",
    "# set adam optimizer\n",
    "optimizer = torch.optim.Adam(lr_mod.parameters(), lr=0.1)\n",
    "\n",
    "# loss functions\n",
    "loss_fn = SPOPlus(optmodel=partial(shortest_path_solver,size=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1bdce795-4469-4349-ad07-e311b6d58c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 72.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.763208389282227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 70.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.725973129272461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 80.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5588157176971436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 80.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.555410623550415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 80.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0469818115234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 78.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9466477632522583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 80.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9816168546676636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 84.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.952664852142334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 83.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.866245985031128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 83.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7920613288879395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "use_gpu = False\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = []\n",
    "    for batch_idx, batch in enumerate(tqdm(dataloader)):\n",
    "            \n",
    "        if use_gpu == True:\n",
    "            for k in batch.keys():\n",
    "                batch[k] = batch[k].cuda()\n",
    "        \n",
    "        # forward pass - prediction\n",
    "        cp = lr_mod(batch['X'])\n",
    "        # optimization get solutions with current predicted costs\n",
    "        #sol, obj = shortest_path_solver(costs=cp, size=5)\n",
    "\n",
    "        # add predicted components to batch\n",
    "        #batch['pred_cost'] = cp\n",
    "        # batch['opt_prob_sol'] = sol\n",
    "        # batch['opt_prob_obj'] = obj\n",
    "        \n",
    "        # Get the function's signature\n",
    "        batch = filter_kwargs(loss_fn.forward, batch)\n",
    "\n",
    "        # loss\n",
    "        #loss = loss_fn(cp.., **batch, pred_cost = pred_cost,...)\n",
    "        loss = loss_fn(cp, **batch)\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "\n",
    "        # TODO: - add in regret calc for validation calc\n",
    "    \n",
    "    print(np.mean(epoch_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b801552-e7ef-45cf-9ab2-69ce272a4ffa",
   "metadata": {},
   "source": [
    "orig loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "705bd441-c848-4841-a163-1aa39c744b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of cores: 1\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "lr_mod = copy.deepcopy(lr_mod_o)\n",
    "# set adam optimizer\n",
    "optimizer = torch.optim.Adam(lr_mod.parameters(), lr=0.1)\n",
    "\n",
    "# loss functions\n",
    "optmodel = shortestPathModel()\n",
    "orig_loss_fn = SPOPlus2_O(optmodel=optmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f45f9bcc-7b50-49a8-94bd-d735a99b8a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 76.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.763208389282227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 81.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.725973129272461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 83.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5588159561157227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 83.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.555410385131836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 83.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0469818115234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 82.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9466477632522583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 81.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9816166162490845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 83.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9526646137237549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 82.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.866245985031128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 82.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7920615673065186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "use_gpu = False\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = []\n",
    "    for batch_idx, batch in enumerate(tqdm(dataloader)):\n",
    "            \n",
    "        if use_gpu == True:\n",
    "            for k in batch.keys():\n",
    "                batch[k] = batch[k].cuda()\n",
    "        \n",
    "        # forward pass - prediction\n",
    "        cp = lr_mod(batch['X'])\n",
    "        # optimization get solutions with current predicted costs\n",
    "        #sol, obj = shortest_path_solver(costs=cp, size=5)\n",
    "\n",
    "        # add predicted components to batch\n",
    "        #batch['pred_cost'] = cp\n",
    "        # batch['opt_prob_sol'] = sol\n",
    "        # batch['opt_prob_obj'] = obj\n",
    "        \n",
    "        # Get the function's signature\n",
    "        batch = filter_kwargs(orig_loss_fn.forward, batch)\n",
    "\n",
    "        # loss\n",
    "        #loss = loss_fn(cp.., **batch, pred_cost = pred_cost,...)\n",
    "        loss = orig_loss_fn(cp, **batch)\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "\n",
    "        # TODO: - add in regret calc for validation calc\n",
    "    \n",
    "    print(np.mean(epoch_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2079619-1b11-47f5-bb6c-47df457c34a5",
   "metadata": {},
   "source": [
    "## Conclusion - yes the new function is the same as the original function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pyepo_dsl)",
   "language": "python",
   "name": "pyepo_dsl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
