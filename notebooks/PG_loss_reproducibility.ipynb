{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba4a4854-1ead-46d6-99e9-d6c3c749dee7",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8893431c-815f-447f-a3c5-bea59c76bf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from functools import partial\n",
    "\n",
    "from torch import nn\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import decision_learning.modeling.pipeline\n",
    "import decision_learning.data.shortest_path_grid\n",
    "\n",
    "from decision_learning.modeling.models import LinearRegression\n",
    "from decision_learning.modeling.pipeline import lossfn_experiment_pipeline, lossfn_hyperparam_grid\n",
    "from decision_learning.data.shortest_path_grid import genData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83ca3f2e-d231-4045-9f83-60ef5844ffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import decision_learning.modeling.train\n",
    "importlib.reload(decision_learning.modeling.train)\n",
    "\n",
    "importlib.reload(decision_learning.modeling.pipeline)\n",
    "from decision_learning.modeling.pipeline import lossfn_experiment_pipeline, lossfn_hyperparam_grid \n",
    "\n",
    "import decision_learning.data.shortest_path_grid\n",
    "importlib.reload(decision_learning.data.shortest_path_grid)\n",
    "from decision_learning.data.shortest_path_grid import genData\n",
    "\n",
    "import decision_learning.modeling.loss\n",
    "importlib.reload(decision_learning.modeling.loss)\n",
    "import decision_learning.modeling.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123eeb04-70e5-445f-b933-0f3a00d3abc7",
   "metadata": {},
   "source": [
    "# Example Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a624754-58e3-448c-91f5-eacdb30885b6",
   "metadata": {},
   "source": [
    "### Optimization Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e1939f-0f64-4d93-95af-07cc8d832179",
   "metadata": {},
   "source": [
    "# Tell people what the optimization model output should look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4f3fd1e-096f-48cb-84b1-15abc4e529cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_path_solver(costs, size, sens = 1e-4):\n",
    "    # Forward Pass\n",
    "    starting_ind = 0\n",
    "    starting_ind_c = 0\n",
    "    samples = costs.shape[0]\n",
    "    V_arr = torch.zeros(samples, size ** 2)\n",
    "    for i in range(0, 2 * (size - 1)):\n",
    "        num_nodes = min(i + 1, 9 - i)\n",
    "        num_nodes_next = min(i + 2, 9 - i - 1)\n",
    "        num_arcs = 2 * (max(num_nodes, num_nodes_next) - 1)\n",
    "        V_1 = V_arr[:, starting_ind:starting_ind + num_nodes]\n",
    "        layer_costs = costs[:, starting_ind_c:starting_ind_c + num_arcs]\n",
    "        l_costs = layer_costs[:, 0::2]\n",
    "        r_costs = layer_costs[:, 1::2]\n",
    "        next_V_val_l = torch.ones(samples, num_nodes_next) * float('inf')\n",
    "        next_V_val_r = torch.ones(samples, num_nodes_next) * float('inf')\n",
    "        if num_nodes_next > num_nodes:\n",
    "            next_V_val_l[:, :num_nodes_next - 1] = V_1 + l_costs\n",
    "            next_V_val_r[:, 1:num_nodes_next] = V_1 + r_costs\n",
    "        else:\n",
    "            next_V_val_l = V_1[:, :num_nodes_next] + l_costs\n",
    "            next_V_val_r = V_1[:, 1:num_nodes_next + 1] + r_costs\n",
    "        next_V_val = torch.minimum(next_V_val_l, next_V_val_r)\n",
    "        V_arr[:, starting_ind + num_nodes:starting_ind + num_nodes + num_nodes_next] = next_V_val\n",
    "\n",
    "        starting_ind += num_nodes\n",
    "        starting_ind_c += num_arcs\n",
    "\n",
    "    # Backward Pass\n",
    "    starting_ind = size ** 2\n",
    "    starting_ind_c = costs.shape[1]\n",
    "    prev_act = torch.ones(samples, 1)\n",
    "    sol = torch.zeros(costs.shape)\n",
    "    for i in range(2 * (size - 1), 0, -1):\n",
    "        num_nodes = min(i + 1, 9 - i)\n",
    "        num_nodes_next = min(i, 9 - i + 1)\n",
    "        V_1 = V_arr[:, starting_ind - num_nodes:starting_ind]\n",
    "        V_2 = V_arr[:, starting_ind - num_nodes - num_nodes_next:starting_ind - num_nodes]\n",
    "\n",
    "        num_arcs = 2 * (max(num_nodes, num_nodes_next) - 1)\n",
    "        layer_costs = costs[:, starting_ind_c - num_arcs: starting_ind_c]\n",
    "\n",
    "        if num_nodes < num_nodes_next:\n",
    "            l_cs_res = ((V_2[:, :num_nodes_next - 1] - V_1 + layer_costs[:, ::2]) < sens) * prev_act\n",
    "            r_cs_res = ((V_2[:, 1:num_nodes_next] - V_1 + layer_costs[:, 1::2]) < sens) * prev_act\n",
    "            prev_act = torch.zeros(V_2.shape)\n",
    "            prev_act[:, :num_nodes_next - 1] += l_cs_res\n",
    "            prev_act[:, 1:num_nodes_next] += r_cs_res\n",
    "        else:\n",
    "            l_cs_res = ((V_2 - V_1[:, :num_nodes - 1] + layer_costs[:, ::2]) < sens) * prev_act[:, :num_nodes - 1]\n",
    "            r_cs_res = ((V_2 - V_1[:, 1:num_nodes] + layer_costs[:, 1::2]) < sens) * prev_act[:, 1:num_nodes]\n",
    "            prev_act = torch.zeros(V_2.shape)\n",
    "            prev_act += l_cs_res\n",
    "            prev_act += r_cs_res\n",
    "        cs = torch.zeros(layer_costs.shape)\n",
    "        cs[:, ::2] = l_cs_res\n",
    "        cs[:, 1::2] = r_cs_res\n",
    "        sol[:, starting_ind_c - num_arcs: starting_ind_c] = cs\n",
    "\n",
    "        starting_ind = starting_ind - num_nodes\n",
    "        starting_ind_c = starting_ind_c - num_arcs\n",
    "    # Dimension (samples, num edges)\n",
    "    obj = torch.sum(sol * costs, axis=1)\n",
    "    # Dimension (samples, 1)\n",
    "    return sol.to(torch.float32), obj.reshape(-1,1).to(torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee65aba-6382-475f-b472-62acb20b1a28",
   "metadata": {},
   "source": [
    "### Data Generation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e50735fd-d2cf-42f1-ab7d-432c2df65eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 unif 0\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(105)\n",
    "indices_arr = torch.randperm(100000)\n",
    "indices_arr_test = torch.randperm(100000)\n",
    "\n",
    "sim = 0\n",
    "n_arr = [200, 400, 800, 1600]\n",
    "ep_arr = ['unif', 'normal']\n",
    "trials = 100\n",
    "\n",
    "exp_arr = []\n",
    "for n in n_arr:\n",
    "    for ep in ep_arr:\n",
    "        for t in range(trials):\n",
    "            exp_arr.append([n, ep, t])\n",
    "\n",
    "# setup\n",
    "exp = exp_arr[0]\n",
    "ep_type = exp[1]\n",
    "trial = exp[2]\n",
    "\n",
    "# generate data\n",
    "grid = (5, 5)  # grid size\n",
    "num_data = exp[0]  # number of training data\n",
    "num_feat = 5  # size of feature\n",
    "deg = 6  # polynomial degree\n",
    "e = .3  # noise width\n",
    "\n",
    "# path planting for shortest path example\n",
    "planted_good_pwl_params = {'slope0':0, \n",
    "                    'int0':2,\n",
    "                    'slope1':0, \n",
    "                    'int1':2}\n",
    "planted_bad_pwl_params = {'slope0':4, \n",
    "                    'int0':0,\n",
    "                    'slope1':0, \n",
    "                    'int1':2.2}\n",
    "\n",
    "plant_edge = True\n",
    "\n",
    "print(num_data, ep_type, trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37eea68c-c535-47cc-8684-62d8da6be9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(exp_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a83848c-8708-4fd9-9017-0489473db9f2",
   "metadata": {},
   "source": [
    "# Testing Pipeline\n",
    "Necessary components\n",
    "- data (features, true costs): train-test splits\n",
    "- prediction model\n",
    "- optimization model\n",
    "- existing loss functions (hyperparameter configs)\n",
    "- custom loss functions\n",
    "- misc params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9e5a109-9fa3-4d7c-8faf-7da91102c9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(decision_learning.modeling.pipeline)\n",
    "from decision_learning.modeling.pipeline import lossfn_experiment_pipeline, lossfn_hyperparam_grid \n",
    "\n",
    "importlib.reload(decision_learning.modeling.train)\n",
    "from decision_learning.modeling.train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bb196e0-ee83-4d83-9fa8-0872f935b733",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ------------DATA------------\n",
    "# training data\n",
    "generated_data = genData(num_data=num_data+200,\n",
    "        num_features=num_feat, \n",
    "        grid=grid, \n",
    "        deg=deg, \n",
    "        noise_type=ep_type,\n",
    "        noise_width=e,\n",
    "        seed=indices_arr[trial],     \n",
    "        plant_edges=plant_edge,\n",
    "        planted_good_pwl_params=planted_good_pwl_params,\n",
    "        planted_bad_pwl_params=planted_bad_pwl_params)\n",
    "# testing data\n",
    "generated_data_test = genData(num_data=10000,\n",
    "        num_features=num_feat, \n",
    "        grid=grid, \n",
    "        deg=deg, \n",
    "        noise_type=ep_type,\n",
    "        noise_width=e,\n",
    "        seed=indices_arr_test[trial],     \n",
    "        plant_edges=plant_edge,\n",
    "        planted_good_pwl_params=planted_good_pwl_params,\n",
    "        planted_bad_pwl_params=planted_bad_pwl_params)\n",
    "\n",
    "# ------------prediction model------------\n",
    "pred_model = LinearRegression(input_dim=generated_data['feat'].shape[1],\n",
    "                 output_dim=generated_data['cost'].shape[1])\n",
    "\n",
    "# ------------optimization model------------\n",
    "optmodel = partial(shortest_path_solver,size=5)\n",
    "\n",
    "# ------------custom loss function------------\n",
    "custom_loss_inputs = [{'loss_name':'cosine',\n",
    "                      'loss':nn.CosineEmbeddingLoss,\n",
    "                      'data': {'X': generated_data['feat'],\n",
    "                               'true_cost':generated_data['cost'],\n",
    "                               'input2':generated_data['cost'], \n",
    "                               'target':torch.ones(generated_data['cost'].shape[0])}\n",
    "                      }\n",
    "                     ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6a69ab-9102-4ede-88a5-355c181aac84",
   "metadata": {},
   "source": [
    "### Get SPO, MSE, Cosine First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2baf9706-3410-4fb2-a3f9-567d9b9884a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 16:37:24,189 - decision_learning.modeling.pipeline - INFO - Loss number 1/4, on loss function SPO+\n",
      "2024-12-10 16:37:24,189 - decision_learning.modeling.pipeline - INFO - Trial 1/1 for running loss function SPO+, current hyperparameters: {}\n",
      "2024-12-10 16:37:26,148 - decision_learning.modeling.pipeline - INFO - Loss number 2/4, on loss function MSE\n",
      "2024-12-10 16:37:26,149 - decision_learning.modeling.pipeline - INFO - Trial 1/1 for running loss function MSE, current hyperparameters: {}\n",
      "2024-12-10 16:37:27,275 - decision_learning.modeling.pipeline - INFO - Loss number 3/4, on loss function FYL\n",
      "2024-12-10 16:37:27,275 - decision_learning.modeling.pipeline - INFO - Trial 1/1 for running loss function FYL, current hyperparameters: {}\n",
      "2024-12-10 16:37:29,064 - decision_learning.modeling.pipeline - INFO - Loss number 4/4, on loss function Cosine\n",
      "2024-12-10 16:37:29,065 - decision_learning.modeling.pipeline - INFO - Trial 1/1 for running loss function Cosine, current hyperparameters: {}\n",
      "2024-12-10 16:37:30,241 - decision_learning.modeling.pipeline - INFO - Trial 1/1 for custom loss functions, current loss function: cosine\n"
     ]
    }
   ],
   "source": [
    "result_metrics, trained_models = lossfn_experiment_pipeline(X_train=generated_data['feat'],\n",
    "                true_cost_train=generated_data['cost'],\n",
    "                X_test=generated_data_test['feat'],\n",
    "                true_cost_test=generated_data_test['cost_true'], \n",
    "                predmodel=pred_model,\n",
    "                optmodel=optmodel,\n",
    "                val_split_params={'test_size':200, 'random_state':42},                                                            \n",
    "                loss_names=['SPO+', 'MSE', 'FYL', 'Cosine'],          \n",
    "                custom_loss_inputs=custom_loss_inputs,                                                            \n",
    "                training_configs={'num_epochs':100,\n",
    "                                  'lr': 0.01,\n",
    "                                 'dataloader_params': {'batch_size':200, 'shuffle':True}},\n",
    "                save_models=True\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9b96e30-15a5-4ce4-a266-cd0509156e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_metric</th>\n",
       "      <th>test_regret</th>\n",
       "      <th>loss_name</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>4.306511</td>\n",
       "      <td>0.211430</td>\n",
       "      <td>0.044372</td>\n",
       "      <td>SPO+</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>99</td>\n",
       "      <td>2.063001</td>\n",
       "      <td>0.465148</td>\n",
       "      <td>0.236546</td>\n",
       "      <td>MSE</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>99</td>\n",
       "      <td>4.205600</td>\n",
       "      <td>0.178077</td>\n",
       "      <td>0.028797</td>\n",
       "      <td>FYL</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>99</td>\n",
       "      <td>0.030852</td>\n",
       "      <td>0.187353</td>\n",
       "      <td>0.072749</td>\n",
       "      <td>Cosine</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>99</td>\n",
       "      <td>0.030852</td>\n",
       "      <td>0.178604</td>\n",
       "      <td>0.072749</td>\n",
       "      <td>cosine</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     epoch  train_loss  val_metric  test_regret loss_name hyperparameters\n",
       "99      99    4.306511    0.211430     0.044372      SPO+              {}\n",
       "199     99    2.063001    0.465148     0.236546       MSE              {}\n",
       "299     99    4.205600    0.178077     0.028797       FYL              {}\n",
       "399     99    0.030852    0.187353     0.072749    Cosine              {}\n",
       "499     99    0.030852    0.178604     0.072749    cosine            None"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_metrics[result_metrics.epoch == 99]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4862c75c-2e94-44e7-9cfc-1c1d7beacfbe",
   "metadata": {},
   "source": [
    "### Input SPO+ as initialization into PG Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "deae4fe8-2eed-4249-8eb0-ac3c0780ab4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPO_trained = trained_models['SPO+_{}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "744e3e9d-c96c-4a34-b794-5b7168cab346",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-10 15:54:08,024 - decision_learning.modeling.pipeline - INFO - Loss number 1/1, on loss function PG\n",
      "2024-12-10 15:54:08,024 - decision_learning.modeling.pipeline - INFO - Trial 1/12 for running loss function PG, current hyperparameters: {'h': 0.5156692688606229, 'finite_diff_type': 'B'}\n",
      "2024-12-10 15:54:09,272 - decision_learning.modeling.pipeline - INFO - Trial 2/12 for running loss function PG, current hyperparameters: {'h': 0.5156692688606229, 'finite_diff_type': 'C'}\n",
      "2024-12-10 15:54:10,517 - decision_learning.modeling.pipeline - INFO - Trial 3/12 for running loss function PG, current hyperparameters: {'h': 0.5156692688606229, 'finite_diff_type': 'F'}\n",
      "2024-12-10 15:54:11,765 - decision_learning.modeling.pipeline - INFO - Trial 4/12 for running loss function PG, current hyperparameters: {'h': 0.26591479484724945, 'finite_diff_type': 'B'}\n",
      "2024-12-10 15:54:13,010 - decision_learning.modeling.pipeline - INFO - Trial 5/12 for running loss function PG, current hyperparameters: {'h': 0.26591479484724945, 'finite_diff_type': 'C'}\n",
      "2024-12-10 15:54:14,255 - decision_learning.modeling.pipeline - INFO - Trial 6/12 for running loss function PG, current hyperparameters: {'h': 0.26591479484724945, 'finite_diff_type': 'F'}\n",
      "2024-12-10 15:54:15,610 - decision_learning.modeling.pipeline - INFO - Trial 7/12 for running loss function PG, current hyperparameters: {'h': 0.07071067811865475, 'finite_diff_type': 'B'}\n",
      "2024-12-10 15:54:16,855 - decision_learning.modeling.pipeline - INFO - Trial 8/12 for running loss function PG, current hyperparameters: {'h': 0.07071067811865475, 'finite_diff_type': 'C'}\n",
      "2024-12-10 15:54:18,094 - decision_learning.modeling.pipeline - INFO - Trial 9/12 for running loss function PG, current hyperparameters: {'h': 0.07071067811865475, 'finite_diff_type': 'F'}\n",
      "2024-12-10 15:54:19,334 - decision_learning.modeling.pipeline - INFO - Trial 10/12 for running loss function PG, current hyperparameters: {'h': 0.005, 'finite_diff_type': 'B'}\n",
      "2024-12-10 15:54:20,569 - decision_learning.modeling.pipeline - INFO - Trial 11/12 for running loss function PG, current hyperparameters: {'h': 0.005, 'finite_diff_type': 'C'}\n",
      "2024-12-10 15:54:21,888 - decision_learning.modeling.pipeline - INFO - Trial 12/12 for running loss function PG, current hyperparameters: {'h': 0.005, 'finite_diff_type': 'F'}\n"
     ]
    }
   ],
   "source": [
    "PG_result_metrics, PG_trained_models = lossfn_experiment_pipeline(X_train=generated_data['feat'],\n",
    "                true_cost_train=generated_data['cost'],\n",
    "                X_test=generated_data_test['feat'],\n",
    "                true_cost_test=generated_data_test['cost_true'], \n",
    "                predmodel=SPO_trained,\n",
    "                optmodel=optmodel,\n",
    "                val_split_params={'test_size':200, 'random_state':42},\n",
    "                loss_names=['PG'],          \n",
    "                loss_configs={'PG': {'h':[num_data**-.125, num_data**-.25, num_data**-.5, num_data**-1], \n",
    "                                     'finite_diff_type': ['B', 'C', 'F']\n",
    "                                    }\n",
    "                             },                \n",
    "                training_configs={'num_epochs':100,\n",
    "                                  'lr': 0.01,\n",
    "                                 'dataloader_params': {'batch_size':200, 'shuffle':True}},\n",
    "                save_models=False\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6dfc5f-5283-4b9b-879c-ba5aab63b2f4",
   "metadata": {},
   "source": [
    "## Combine Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4a9e8ae-1f99-44a5-b380-3a4c76dc39ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_metrics = pd.concat([result_metrics, PG_result_metrics], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67300402-4853-43af-b6ce-17e351d735a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_metric</th>\n",
       "      <th>test_regret</th>\n",
       "      <th>loss_name</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>71</td>\n",
       "      <td>14.273172</td>\n",
       "      <td>0.156225</td>\n",
       "      <td>0.014403</td>\n",
       "      <td>PG</td>\n",
       "      <td>{'h': 0.5156692688606229, 'finite_diff_type': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>97</td>\n",
       "      <td>4.174900</td>\n",
       "      <td>0.172062</td>\n",
       "      <td>0.029759</td>\n",
       "      <td>FYL</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>53</td>\n",
       "      <td>0.030131</td>\n",
       "      <td>0.143116</td>\n",
       "      <td>0.045167</td>\n",
       "      <td>cosine</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>88</td>\n",
       "      <td>4.287334</td>\n",
       "      <td>0.195468</td>\n",
       "      <td>0.047049</td>\n",
       "      <td>SPO+</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>95</td>\n",
       "      <td>2.152484</td>\n",
       "      <td>0.438158</td>\n",
       "      <td>0.241357</td>\n",
       "      <td>MSE</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     epoch  train_loss  val_metric  test_regret loss_name  \\\n",
       "571     71   14.273172    0.156225     0.014403        PG   \n",
       "297     97    4.174900    0.172062     0.029759       FYL   \n",
       "353     53    0.030131    0.143116     0.045167    cosine   \n",
       "88      88    4.287334    0.195468     0.047049      SPO+   \n",
       "195     95    2.152484    0.438158     0.241357       MSE   \n",
       "\n",
       "                                       hyperparameters  \n",
       "571  {'h': 0.5156692688606229, 'finite_diff_type': ...  \n",
       "297                                                 {}  \n",
       "353                                               None  \n",
       "88                                                  {}  \n",
       "195                                                 {}  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_metrics.loc[final_metrics.groupby('loss_name')['val_metric'].idxmin()].sort_values(by='test_regret')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pyepo_dsl)",
   "language": "python",
   "name": "pyepo_dsl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
